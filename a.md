| Paper                                                                 | Conference/Journal | Year | Architecture                                                | Dataset                              | Novel mAP                                       | Known mAP                                        | U-Recall (%)                          | Key Innovation |
|-----------------------------------------------------------------------|--------------------|------|-------------------------------------------------------------|--------------------------------------|--------------------------------------------------|---------------------------------------------------|----------------------------------------|----------------|
| Enhancing Novel Object Detection via Cooperative Foundational Models (BASE) | WACV               | 2025 | GDINO detector + CLIP vision–language encoder + SAM segmenter with cooperative score fusion | LVIS (NOD split), COCO (OVD split)   | **17.42** (LVIS novel mAP@[0.5:0.95])  | **42.08** (LVIS known mAP@[0.5:0.95])  | N/A                                    | Cooperative mechanism that fuses scores from foundational models (CLIP, SAM) and a strong detector (GDINO) to turn a closed-set detector into a **training-free novel object detector** with SOTA LVIS performance.  |
| Unsupervised Annotation and Detection of Novel Objects Using Known Objectness | VISAPP (VISIGRAPP) | 2024 | Class-agnostic objectness detector (OLN / MAVL) + feature clustering + retrained YOLOv7 detector | LMDet / COCO-style long-tail data    | Improves novel-class mAP over base OLN/MAVL; e.g. “sports ball” mAP@0.5 rises from **0.705 → 0.902** after retraining  | N/A                                               | N/A                                    | Uses **pre-trained objectness models** to propose regions, then web-image search and clustering to build a weakly labelled dataset and retrain a detector, significantly boosting mAP on novel classes without manual annotation.  |
| Detection of Novel Objects without Fine-Tuning in Assembly Scenarios | Automation / MDPI AI | 2024 | Class-agnostic 2D detector (trained once on LVIS) + metric-learning ReID head for tool instances | ATTACH, IKEA-ASM (assembly lines)    | mAP on novel tools in the mid-20s to mid-30s depending on shot count (e.g. ~26–35 mAP on IKEA-ASM few-shot)  | N/A                                               | N/A                                    | Introduces a **class-agnostic detector + object re-identification pipeline** that can detect and track **novel industrial tools** from a few example images **without fine-tuning on those new objects**.  |
| Learning to Detect Novel Species with SAM in the Wild                | IJCV               | 2024/25 | Faster R-CNN-style detector + novelty-aware student model guided by SAM masks | Multiple wildlife & plant datasets (camera-traps, crops, etc.) | COCO-style AP for novel species; reported AP for novel species ranges roughly **56–62** depending on scenario  | N/A                                               | N/A                                    | Combines **Segment Anything Model (SAM)** with novelty detection and a student–teacher detector to **discover and detect new animal/plant species** with strong AP on novel classes in real-world data.  |
| Few-shot Learning for Novel Object Detection in Autonomous Driving   | Communications in Transportation Research | 2025 | One-stage few-shot detector tailored to road scenes (feature aggregation for rare classes) | Real autonomous-driving dataset + PASCAL VOC FSOD | mAP for rare / novel categories (exact values inside paper; abstract reports state-of-the-art accuracy)  | N/A                                               | N/A                                    | Proposes a **few-shot NOD framework** for autonomous driving that achieves state-of-the-art accuracy and better inference speed on rare road objects compared with competing few-shot detectors.  |
| Collaborative Novel Object Discovery and Box-Guided Open-Vocabulary 3D Object Detection (CoDAv2) | TPAMI              | 2025 | 3D detector backbone + 3D Novel Object Discovery (3D-NOD) + Discovery-driven Cross-Modal Alignment (DCMA) with 2D boxes | OV-SUN-RGBD, OV-ScanNetv2 (3D OV/NOD) | **AP_Novel = 9.17 vs 3.61** on SUN-RGBD; **9.12 vs 3.74** on ScanNetv2 (previous best)  | N/A                                               | N/A                                    | Unified **3D novel object discovery + open-vocabulary 3D detection** framework; 3D-NOD + Box-DCMA give **>2× improvement in novel-class AP** on both SUN-RGBD and ScanNetv2.  |
| Open-World Objectness Modeling Unifies Novel Object Detection (OWOBJ) | CVPR               | 2025 | OWOBJ objectness head plugged into OW-DETR/PROB pipelines (transformer-based detector) | M-OWODB & S-OWODB (COCO-based OWOD) | N/A (OWOD evaluates unknowns via U-Recall, not novel mAP) | Baseline known mAP@0.5 improved by about **+3 mAP** over PROB on both M-OWODB and S-OWODB  | **Higher U-Recall with much lower A-OSE; U-Recall increased significantly vs prior OWOD methods** (Task-wise gains up to ~+5–19 points)  | Models **objectness distribution** directly to improve detection of unknown objects in open-world settings, serving as a flexible plugin that boosts OWOD, few-shot OD, and zero-shot OVOD performance.  |
| VL-SAM: Training-Free Open-Ended Object Detection and Segmentation via Attention as Prompts | NeurIPS            | 2024 | VLM (vision–language model) + SAM; VL attention maps aggregated and used as point prompts for SAM | LVIS (long-tail), CODA (corner-case OD) | N/A (reports detection mAP and segmentation AP/mIoU, not classic “novel mAP” split)  | N/A                                               | CODA: **mAR = 40.1** vs **18.4** for LLaVA-Grounding (large gain), while being training-free  | First **training-free open-ended OD/seg** method that links a VLM and SAM through attention maps; substantially improves detection/segmentation on LVIS and CODA over previous open-ended and open-set methods without any extra training.  |
| SearchDet: Search and Detect – Training-Free Long Tail Object Detection via Web-Image Retrieval | CVPR               | 2025 | GroundingDINO-style OVOD backbone + web-image retrieval module that builds image-conditioned queries | ODinW, LVIS (long-tail / OVOD)       | ODinW: **+48.7 mAP improvement** over GroundingDINO; LVIS: **+59.1 mAP improvement** over GroundingDINO (relative gains)  | N/A                                               | N/A                                    | **Training-free long-tail/OVOD** framework: retrieves positive & negative web exemplars, embeds them, and forms a weighted query to detect rare/novel concepts, dramatically boosting OVOD mAP without any additional training.  |
| Advancing Open-Set Object Detection in Remote Sensing Using Multimodal Large Language Model | WACV Workshops (GeoCV) | 2025 | Closed-set RS detector + proposal generation + RemoteCLIP similarity + Multimodal LLM to name unknowns | DOTA, DIOR, NWPU VHR-10 (remote sensing) | N/A (focuses on open-set detection + discovery, not LVIS-style novel mAP) | Known-class mAP improved over baseline RS detector (exact values per dataset in tables)  | N/A (uses open-set metrics like open-set accuracy rather than classic U-Recall) | Two-step pipeline for remote sensing: (1) **open-set object region detection** with a closed-set detector, (2) **semantic discovery** of unknown regions via MLLM + RemoteCLIP, enabling automatic labeling of novel RS object categories without manual annotation.  |
